{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6ed7f95-36c1-480b-9a16-8c22cfbca66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1747 images to trainimages.txt\n",
      "Saved 697 images to validationimages.txt\n"
     ]
    }
   ],
   "source": [
    "# Genrate name files\n",
    "import os\n",
    "\n",
    "# Path to your dataset folders\n",
    "train_dir = \"dataset/Freshwater Fish Disease Aquaculture in south asia/Train\"\n",
    "val_dir   = \"dataset/Freshwater Fish Disease Aquaculture in south asia/Test\"\n",
    "\n",
    "# Output text files\n",
    "train_file = \"trainimages.txt\"\n",
    "val_file   = \"validationimages.txt\"\n",
    "\n",
    "def save_image_list(directory, output_file):\n",
    "    \"\"\"\n",
    "    Walks through subfolders in a directory and writes all image filenames to a text file.\n",
    "    \"\"\"\n",
    "    image_list = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.jpg', '.jpeg', '.png')):  # only images\n",
    "                image_list.append(file)\n",
    "\n",
    "    # Save to text file\n",
    "    with open(output_file, 'w') as f:\n",
    "        for filename in image_list:\n",
    "            f.write(filename + \"\\n\")\n",
    "\n",
    "    print(f\"Saved {len(image_list)} images to {output_file}\")\n",
    "\n",
    "# Generate train and validation image lists\n",
    "save_image_list(train_dir, train_file)\n",
    "save_image_list(val_dir, val_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edeba2fa-c2c8-4607-9651-1e9b4f1fe50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptions saved to train_descriptions.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set this to your train or test folder path\n",
    "BASE_DIR = \"dataset/Freshwater Fish Disease Aquaculture in south asia/Train\"\n",
    "OUTPUT_FILE = \"train_descriptions.txt\"\n",
    "\n",
    "# List of your class names (folder names)\n",
    "class_names = [\n",
    "    'Bacterial Red disease',\n",
    "    'Bacterial diseases - Aeromoniasis',\n",
    "    'Bacterial gill disease',\n",
    "    'Fungal diseases Saprolegniasis',\n",
    "    'Healthy Fish',\n",
    "    'Parasitic diseases',\n",
    "    'Viral diseases White tail disease'\n",
    "]\n",
    "\n",
    "# Simple template captions per image\n",
    "caption_templates = [\n",
    "    \"A fish showing symptoms of {}\",\n",
    "    \"This fish is affected by {}\",\n",
    "    \"{} symptoms are visible on the fish\",\n",
    "    \"Signs of {} are present on this fish\",\n",
    "    \"The fish has indications of {}\"\n",
    "]\n",
    "\n",
    "with open(OUTPUT_FILE, \"w\") as f_out:\n",
    "    for class_name in class_names:\n",
    "        class_path = os.path.join(BASE_DIR, class_name)\n",
    "        if not os.path.exists(class_path):\n",
    "            print(f\"Folder not found: {class_path}\")\n",
    "            continue\n",
    "        for img_file in os.listdir(class_path):\n",
    "            if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                for idx, template in enumerate(caption_templates):\n",
    "                    caption = template.format(class_name)\n",
    "                    f_out.write(f\"{img_file}#{idx} {caption}\\n\")\n",
    "\n",
    "print(f\"Descriptions saved to {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a7038d7-4344-4efc-bc93-82a08d01afc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptions saved to test_descriptions.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set this to your train or test folder path\n",
    "BASE_DIR = \"dataset/Freshwater Fish Disease Aquaculture in south asia/Test\"\n",
    "OUTPUT_FILE = \"test_descriptions.txt\"\n",
    "\n",
    "# List of your class names (folder names)\n",
    "class_names = [\n",
    "    'Bacterial Red disease',\n",
    "    'Bacterial diseases - Aeromoniasis',\n",
    "    'Bacterial gill disease',\n",
    "    'Fungal diseases Saprolegniasis',\n",
    "    'Healthy Fish',\n",
    "    'Parasitic diseases',\n",
    "    'Viral diseases White tail disease'\n",
    "]\n",
    "\n",
    "# Simple template captions per image\n",
    "caption_templates = [\n",
    "    \"A fish showing symptoms of {}\",\n",
    "    \"This fish is affected by {}\",\n",
    "    \"{} symptoms are visible on the fish\",\n",
    "    \"Signs of {} are present on this fish\",\n",
    "    \"The fish has indications of {}\"\n",
    "]\n",
    "\n",
    "with open(OUTPUT_FILE, \"w\") as f_out:\n",
    "    for class_name in class_names:\n",
    "        class_path = os.path.join(BASE_DIR, class_name)\n",
    "        if not os.path.exists(class_path):\n",
    "            print(f\"Folder not found: {class_path}\")\n",
    "            continue\n",
    "        for img_file in os.listdir(class_path):\n",
    "            if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                for idx, template in enumerate(caption_templates):\n",
    "                    caption = template.format(class_name)\n",
    "                    f_out.write(f\"{img_file}#{idx} {caption}\\n\")\n",
    "\n",
    "print(f\"Descriptions saved to {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb87fa1a-f9df-4a3f-8e11-fde8dcb67e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\atchaya\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\atchaya\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\atchaya\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset/Freshwater Fish Disease Aquaculture in south asia/Train: 0it [00:00, ?it/s]\n",
      "Processing dataset/Freshwater Fish Disease Aquaculture in south asia/Train: 100%|████| 250/250 [00:56<00:00,  4.41it/s]\n",
      "Processing dataset/Freshwater Fish Disease Aquaculture in south asia/Train: 100%|████| 250/250 [00:48<00:00,  5.14it/s]\n",
      "Processing dataset/Freshwater Fish Disease Aquaculture in south asia/Train: 100%|████| 250/250 [00:49<00:00,  5.08it/s]\n",
      "Processing dataset/Freshwater Fish Disease Aquaculture in south asia/Train: 100%|████| 250/250 [01:00<00:00,  4.15it/s]\n",
      "Processing dataset/Freshwater Fish Disease Aquaculture in south asia/Train: 100%|████| 250/250 [01:13<00:00,  3.41it/s]\n",
      "Processing dataset/Freshwater Fish Disease Aquaculture in south asia/Train: 100%|████| 250/250 [01:12<00:00,  3.46it/s]\n",
      "Processing dataset/Freshwater Fish Disease Aquaculture in south asia/Train: 100%|████| 250/250 [01:09<00:00,  3.62it/s]\n",
      "Processing dataset/Freshwater Fish Disease Aquaculture in south asia/Test: 0it [00:00, ?it/s]\n",
      "Processing dataset/Freshwater Fish Disease Aquaculture in south asia/Test: 100%|█████| 100/100 [00:27<00:00,  3.58it/s]\n",
      "Processing dataset/Freshwater Fish Disease Aquaculture in south asia/Test: 100%|█████| 100/100 [00:27<00:00,  3.68it/s]\n",
      "Processing dataset/Freshwater Fish Disease Aquaculture in south asia/Test: 100%|█████| 100/100 [00:31<00:00,  3.14it/s]\n",
      "Processing dataset/Freshwater Fish Disease Aquaculture in south asia/Test: 100%|█████| 100/100 [00:27<00:00,  3.65it/s]\n",
      "Processing dataset/Freshwater Fish Disease Aquaculture in south asia/Test: 100%|█████| 100/100 [00:29<00:00,  3.43it/s]\n",
      "Processing dataset/Freshwater Fish Disease Aquaculture in south asia/Test: 100%|█████| 100/100 [00:27<00:00,  3.68it/s]\n",
      "Processing dataset/Freshwater Fish Disease Aquaculture in south asia/Test: 100%|█████| 100/100 [00:26<00:00,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train features to features_train.pkl\n",
      "Saved validation features to features_val.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.applications import DenseNet201\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Paths to dataset\n",
    "train_dir = \"dataset/Freshwater Fish Disease Aquaculture in south asia/Train\"\n",
    "val_dir   = \"dataset/Freshwater Fish Disease Aquaculture in south asia/Test\"\n",
    "\n",
    "# Output pickle files\n",
    "train_features_file = \"features_train.pkl\"\n",
    "val_features_file   = \"features_val.pkl\"\n",
    "\n",
    "# Load DenseNet201 without top\n",
    "conv_base = DenseNet201(weights='imagenet', include_top=False, pooling='avg')  # pooling='avg' to get 1920-d vector\n",
    "\n",
    "def extract_features(directory):\n",
    "    features = {}\n",
    "    # Walk through all subfolders and images\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in tqdm(files, desc=f\"Processing {directory}\"):\n",
    "            if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                filepath = os.path.join(root, file)\n",
    "                # Load image\n",
    "                image = load_img(filepath, target_size=(224, 224))\n",
    "                image = img_to_array(image)\n",
    "                image = np.expand_dims(image, axis=0)\n",
    "                image = preprocess_input(image)\n",
    "                # Extract features\n",
    "                feature = conv_base.predict(image, verbose=0)\n",
    "                # Save with filename (without extension) as key\n",
    "                key = os.path.splitext(file)[0]\n",
    "                features[key] = feature\n",
    "    return features\n",
    "\n",
    "# Extract train and validation features\n",
    "train_features = extract_features(train_dir)\n",
    "val_features   = extract_features(val_dir)\n",
    "\n",
    "# Save features to pickle\n",
    "with open(train_features_file, 'wb') as f:\n",
    "    pickle.dump(train_features, f)\n",
    "print(f\"Saved train features to {train_features_file}\")\n",
    "\n",
    "with open(val_features_file, 'wb') as f:\n",
    "    pickle.dump(val_features, f)\n",
    "print(f\"Saved validation features to {val_features_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69ad3e03-fd30-4552-9254-c5c91acdb5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images: 1639\n",
      "Validation images: 589\n"
     ]
    }
   ],
   "source": [
    "# =====================================\n",
    "#  Fish Image Captioning - DenseNet201 + LSTM\n",
    "# =====================================\n",
    "import os\n",
    "import numpy as np\n",
    "from pickle import load, dump\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, add\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Utility Functions\n",
    "# ----------------------------\n",
    "\n",
    "def load_doc(filename):\n",
    "    \"\"\"Load text file into memory.\"\"\"\n",
    "    with open(filename, 'r') as file:\n",
    "        text = file.read()\n",
    "    return text\n",
    "\n",
    "def load_set(filename):\n",
    "    \"\"\"Load image names (without extension) from a file.\"\"\"\n",
    "    doc = load_doc(filename)\n",
    "    dataset = [line.split('.')[0] for line in doc.split('\\n') if len(line) > 0]\n",
    "    return set(dataset)\n",
    "\n",
    "def load_clean_descriptions(filename, dataset):\n",
    "    \"\"\"Load clean descriptions for given dataset image IDs.\"\"\"\n",
    "    doc = load_doc(filename)\n",
    "    descriptions = {}\n",
    "    for line in doc.split('\\n'):\n",
    "        tokens = line.split('#')\n",
    "        if len(tokens) < 2:\n",
    "            continue\n",
    "        image_id_no = tokens[1][0]\n",
    "        image_id, image_desc = tokens[0].split(\".\")[0], tokens[1][1:].strip()\n",
    "        if image_id in dataset:\n",
    "            if image_id not in descriptions:\n",
    "                descriptions[image_id] = []\n",
    "            desc = 'startseq ' + image_desc + ' endseq'\n",
    "            descriptions[image_id].append(desc)\n",
    "    return descriptions\n",
    "\n",
    "def load_photo_features(filename, dataset):\n",
    "    \"\"\"Load pre-extracted DenseNet201 features (1920-D) from pickle file.\"\"\"\n",
    "    all_features = load(open(filename, 'rb'))\n",
    "    features = {k: all_features[k] for k in dataset if k in all_features}\n",
    "    return features\n",
    "\n",
    "def to_lines(descriptions):\n",
    "    \"\"\"Flatten a dictionary of descriptions to a list.\"\"\"\n",
    "    all_desc = []\n",
    "    for key in descriptions.keys():\n",
    "        all_desc.extend(descriptions[key])\n",
    "    return all_desc\n",
    "\n",
    "def create_tokenizer(descriptions):\n",
    "    \"\"\"Create a tokenizer from the training descriptions.\"\"\"\n",
    "    lines = to_lines(descriptions)\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer\n",
    "\n",
    "def max_length(descriptions):\n",
    "    \"\"\"Calculate the maximum caption length.\"\"\"\n",
    "    lines = to_lines(descriptions)\n",
    "    return max(len(d.split()) for d in lines)\n",
    "\n",
    "def create_sequences(tokenizer, max_length, descriptions, photos, vocab_size):\n",
    "    \"\"\"Create input-output sequences for the model.\"\"\"\n",
    "    X1, X2, y = [], [], []\n",
    "    for key, desc_list in descriptions.items():\n",
    "        for desc in desc_list:\n",
    "            seq = tokenizer.texts_to_sequences([desc])[0]\n",
    "            for i in range(1, len(seq)):\n",
    "                in_seq, out_seq = seq[:i], seq[i]\n",
    "                in_seq = pad_sequences([in_seq], maxlen=max_length, padding=\"post\")[0]\n",
    "                out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "                X1.append(photos[key][0])  # DenseNet201 feature\n",
    "                X2.append(in_seq)\n",
    "                y.append(out_seq)\n",
    "    return np.array(X1), np.array(X2), np.array(y)\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Model Definition\n",
    "# ----------------------------\n",
    "\n",
    "def define_model(vocab_size, max_length):\n",
    "    \"\"\"Define the DenseNet201 + LSTM captioning model.\"\"\"\n",
    "    # Feature extractor branch\n",
    "    inputs1 = Input(shape=(1920,))  # <-- DenseNet201 output dimension\n",
    "    fe1 = Dropout(0.5)(inputs1)\n",
    "    fe2 = Dense(256, activation='relu')(fe1)\n",
    "\n",
    "    # Sequence processor branch\n",
    "    inputs2 = Input(shape=(max_length,))\n",
    "    se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
    "    se2 = Dropout(0.5)(se1)\n",
    "    se3 = LSTM(256)(se2)\n",
    "\n",
    "    # Decoder (merge)\n",
    "    decoder1 = add([fe2, se3])\n",
    "    decoder2 = Dense(256, activation='relu')(decoder1)\n",
    "    outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
    "\n",
    "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    print(model.summary())\n",
    "    plot_model(model, to_file='fish_caption_model.png', show_shapes=True)\n",
    "    return model\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Load Datasets\n",
    "# ----------------------------\n",
    "\n",
    "train_images_file = 'trainimages.txt'\n",
    "val_images_file   = 'validationimages.txt'\n",
    "train_descriptions_file = 'train_descriptions.txt'\n",
    "val_descriptions_file   = 'test_descriptions.txt'\n",
    "train_features_file = 'features_train.pkl'\n",
    "val_features_file   = 'features_val.pkl'\n",
    "\n",
    "# Training data\n",
    "train_set = load_set(train_images_file)\n",
    "train_descriptions = load_clean_descriptions(train_descriptions_file, train_set)\n",
    "train_features = load_photo_features(train_features_file, train_set)\n",
    "\n",
    "# Validation data\n",
    "val_set = load_set(val_images_file)\n",
    "val_descriptions = load_clean_descriptions(val_descriptions_file, val_set)\n",
    "val_features = load_photo_features(val_features_file, val_set)\n",
    "\n",
    "print(f\"Training images: {len(train_set)}\")\n",
    "print(f\"Validation images: {len(val_set)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "283ebeef-82c2-4bdb-8c75-73be9f390bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 33\n",
      "Max caption length: 14\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 4. Tokenizer and Data Prep\n",
    "# ----------------------------\n",
    "\n",
    "tokenizer = create_tokenizer(train_descriptions)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "max_len = max_length(train_descriptions)\n",
    "\n",
    "print(f\"Vocab size: {vocab_size}\")\n",
    "print(f\"Max caption length: {max_len}\")\n",
    "\n",
    "# Save tokenizer for inference later\n",
    "with open('tokenizer.pkl', 'wb') as f:\n",
    "    dump(tokenizer, f)\n",
    "\n",
    "# Create train and validation sequences\n",
    "X1train, X2train, ytrain = create_sequences(tokenizer, max_len, train_descriptions, train_features, vocab_size)\n",
    "X1val, X2val, yval = create_sequences(tokenizer, max_len, val_descriptions, val_features, vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "637f9431-6f84-4d75-ab90-a182a6448191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1639\n",
      "['Bacterial diseases - Aeromoniasis (209)', 'Healthy Fish (103)', 'Parasitic diseases (229)', 'Bacterial Red disease (134)', 'Parasitic diseases (115)', 'Parasitic diseases (67)', 'Healthy Fish (12)', 'Healthy Fish (15)', 'Bacterial diseases - Aeromoniasis (172)', 'Healthy Fish (223)']\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set))\n",
    "print(list(train_set)[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "850e2768-ae75-4c50-97a8-b087175d01ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)        [(None, 14)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)        [(None, 1920)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, 14, 256)              8448      ['input_5[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 1920)                 0         ['input_4[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 14, 256)              0         ['embedding_1[0][0]']         \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 256)                  491776    ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               (None, 256)                  525312    ['dropout_3[0][0]']           \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 256)                  0         ['dense_3[0][0]',             \n",
      "                                                                     'lstm_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 256)                  65792     ['add_1[0][0]']               \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 33)                   8481      ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1099809 (4.20 MB)\n",
      "Trainable params: 1099809 (4.20 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "Epoch 1/30\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.22255, saving model to best_fish_caption_model.hdf5\n",
      "1310/1310 - 115s - loss: 0.5346 - val_loss: 0.2225 - 115s/epoch - 88ms/step\n",
      "Epoch 2/30\n",
      "\n",
      "Epoch 2: val_loss improved from 0.22255 to 0.20541, saving model to best_fish_caption_model.hdf5\n",
      "1310/1310 - 107s - loss: 0.2483 - val_loss: 0.2054 - 107s/epoch - 82ms/step\n",
      "Epoch 3/30\n",
      "\n",
      "Epoch 3: val_loss improved from 0.20541 to 0.19295, saving model to best_fish_caption_model.hdf5\n",
      "1310/1310 - 108s - loss: 0.2256 - val_loss: 0.1930 - 108s/epoch - 82ms/step\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 4: val_loss improved from 0.19295 to 0.17749, saving model to best_fish_caption_model.hdf5\n",
      "1310/1310 - 102s - loss: 0.2120 - val_loss: 0.1775 - 102s/epoch - 78ms/step\n",
      "Epoch 5/30\n",
      "\n",
      "Epoch 5: val_loss improved from 0.17749 to 0.17611, saving model to best_fish_caption_model.hdf5\n",
      "1310/1310 - 104s - loss: 0.2033 - val_loss: 0.1761 - 104s/epoch - 79ms/step\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 6: val_loss improved from 0.17611 to 0.17398, saving model to best_fish_caption_model.hdf5\n",
      "1310/1310 - 110s - loss: 0.1989 - val_loss: 0.1740 - 110s/epoch - 84ms/step\n",
      "Epoch 7/30\n",
      "\n",
      "Epoch 7: val_loss improved from 0.17398 to 0.17316, saving model to best_fish_caption_model.hdf5\n",
      "1310/1310 - 109s - loss: 0.1926 - val_loss: 0.1732 - 109s/epoch - 83ms/step\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 8: val_loss improved from 0.17316 to 0.17197, saving model to best_fish_caption_model.hdf5\n",
      "1310/1310 - 111s - loss: 0.1921 - val_loss: 0.1720 - 111s/epoch - 85ms/step\n",
      "Epoch 9/30\n",
      "\n",
      "Epoch 9: val_loss improved from 0.17197 to 0.17102, saving model to best_fish_caption_model.hdf5\n",
      "1310/1310 - 99s - loss: 0.1873 - val_loss: 0.1710 - 99s/epoch - 76ms/step\n",
      "Epoch 10/30\n",
      "\n",
      "Epoch 10: val_loss improved from 0.17102 to 0.17069, saving model to best_fish_caption_model.hdf5\n",
      "1310/1310 - 97s - loss: 0.1859 - val_loss: 0.1707 - 97s/epoch - 74ms/step\n",
      "Epoch 11/30\n",
      "\n",
      "Epoch 11: val_loss improved from 0.17069 to 0.17034, saving model to best_fish_caption_model.hdf5\n",
      "1310/1310 - 102s - loss: 0.1859 - val_loss: 0.1703 - 102s/epoch - 78ms/step\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 12: val_loss improved from 0.17034 to 0.16969, saving model to best_fish_caption_model.hdf5\n",
      "1310/1310 - 97s - loss: 0.1822 - val_loss: 0.1697 - 97s/epoch - 74ms/step\n",
      "Epoch 13/30\n",
      "\n",
      "Epoch 13: val_loss improved from 0.16969 to 0.16954, saving model to best_fish_caption_model.hdf5\n",
      "1310/1310 - 101s - loss: 0.1832 - val_loss: 0.1695 - 101s/epoch - 77ms/step\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.16954\n",
      "1310/1310 - 117s - loss: 0.1827 - val_loss: 0.1699 - 117s/epoch - 89ms/step\n",
      "Epoch 15/30\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.16954\n",
      "1310/1310 - 111s - loss: 0.1801 - val_loss: 0.1696 - 111s/epoch - 85ms/step\n",
      "Epoch 16/30\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.16954\n",
      "1310/1310 - 98s - loss: 0.1804 - val_loss: 0.1696 - 98s/epoch - 75ms/step\n",
      "Epoch 17/30\n",
      "\n",
      "Epoch 17: val_loss improved from 0.16954 to 0.16942, saving model to best_fish_caption_model.hdf5\n",
      "1310/1310 - 96s - loss: 0.1800 - val_loss: 0.1694 - 96s/epoch - 73ms/step\n",
      "Epoch 18/30\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.16942\n",
      "1310/1310 - 97s - loss: 0.1799 - val_loss: 0.1698 - 97s/epoch - 74ms/step\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.16942\n",
      "1310/1310 - 103s - loss: 0.1805 - val_loss: 0.1695 - 103s/epoch - 79ms/step\n",
      "Epoch 20/30\n",
      "\n",
      "Epoch 20: val_loss improved from 0.16942 to 0.16921, saving model to best_fish_caption_model.hdf5\n",
      "1310/1310 - 96s - loss: 0.1801 - val_loss: 0.1692 - 96s/epoch - 73ms/step\n",
      "Epoch 21/30\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.16921\n",
      "1310/1310 - 103s - loss: 0.1780 - val_loss: 0.1696 - 103s/epoch - 79ms/step\n",
      "Epoch 22/30\n",
      "\n",
      "Epoch 22: val_loss improved from 0.16921 to 0.16892, saving model to best_fish_caption_model.hdf5\n",
      "1310/1310 - 98s - loss: 0.1787 - val_loss: 0.1689 - 98s/epoch - 75ms/step\n",
      "Epoch 23/30\n",
      "\n",
      "Epoch 23: val_loss improved from 0.16892 to 0.16890, saving model to best_fish_caption_model.hdf5\n",
      "1310/1310 - 100s - loss: 0.1781 - val_loss: 0.1689 - 100s/epoch - 76ms/step\n",
      "Epoch 24/30\n",
      "\n",
      "Epoch 24: val_loss improved from 0.16890 to 0.16876, saving model to best_fish_caption_model.hdf5\n",
      "1310/1310 - 102s - loss: 0.1776 - val_loss: 0.1688 - 102s/epoch - 78ms/step\n",
      "Epoch 25/30\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.16876\n",
      "1310/1310 - 103s - loss: 0.1767 - val_loss: 0.1696 - 103s/epoch - 79ms/step\n",
      "Epoch 26/30\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.16876\n",
      "1310/1310 - 96s - loss: 0.1769 - val_loss: 0.1692 - 96s/epoch - 73ms/step\n",
      "Epoch 27/30\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.16876\n",
      "1310/1310 - 96s - loss: 0.1772 - val_loss: 0.1693 - 96s/epoch - 73ms/step\n",
      "Epoch 28/30\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.16876\n",
      "1310/1310 - 97s - loss: 0.1772 - val_loss: 0.1689 - 97s/epoch - 74ms/step\n",
      "Epoch 29/30\n",
      "\n",
      "Epoch 29: val_loss improved from 0.16876 to 0.16872, saving model to best_fish_caption_model.hdf5\n",
      "1310/1310 - 96s - loss: 0.1769 - val_loss: 0.1687 - 96s/epoch - 73ms/step\n",
      "Epoch 30/30\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.16872\n",
      "1310/1310 - 95s - loss: 0.1762 - val_loss: 0.1689 - 95s/epoch - 73ms/step\n",
      "✅ Training complete. Best model saved as 'best_fish_caption_model.hdf5' and final model as 'final_fish_caption_model.hdf5'.\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 5. Define and Train Model\n",
    "# ----------------------------\n",
    "\n",
    "model = define_model(vocab_size, max_len)\n",
    "\n",
    "# Save the best model (lowest val_loss) during training in .hdf5 format\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_fish_caption_model.hdf5',  # <-- note the .hdf5 extension\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    [X1train, X2train], ytrain,\n",
    "    epochs=30,\n",
    "    verbose=2,\n",
    "    batch_size=64,\n",
    "    validation_data=([X1val, X2val], yval),\n",
    "    callbacks=[checkpoint]\n",
    ")\n",
    "\n",
    "# After training, load the best weights before final saving\n",
    "model.load_weights('best_fish_caption_model.hdf5')\n",
    "\n",
    "# Save final model again (same best weights, but as a full Model object)\n",
    "model.save('final_fish_caption_model.hdf5')\n",
    "\n",
    "print(\"✅ Training complete. Best model saved as 'best_fish_caption_model.hdf5' and final model as 'final_fish_caption_model.hdf5'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b7fb0d3-bc6a-408e-83da-f4bde5910832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(len(train_descriptions))\n",
    "print(list(train_descriptions.items())[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9d371d-b84d-43b1-9f4b-514276cbc8d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
